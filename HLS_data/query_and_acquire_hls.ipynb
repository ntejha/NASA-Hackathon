{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Query CMR STAC for HLS data given a point location and date range\n",
    "Return a list of asset filenames for AWS or HTTPS access\n",
    "Translate to local filenames and download\n",
    "'''\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas\n",
    "import requests\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from pystac_client import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which collections to search\n",
    "collections = ['HLSL30.v2.0', 'HLSS30.v2.0']\n",
    "\n",
    "# define the point location/centroid for the HLS tile we want\n",
    "pt = json.loads('{\"type\":\"Point\", \"coordinates\":[-105.530017, 40.15442]}')\n",
    "\n",
    "# define the dates we want to query\n",
    "#date_range = \"2021-05-01T00:00:00Z/2021-08-30T23:59:59Z\"    # closed interval\n",
    "#date_range = \"2021-05-01T00:00:00Z/..\"                      # open interval - does not currently work with the CMR-STAC API\n",
    "#date_range = \"2021-05/2021-11\"\n",
    "start_date = datetime(year=2021, day=1, month=1)\n",
    "end_date = datetime(year=2021, day=31, month=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def search_stac_for_HLS(pt, dt_min, dt_max, cloudcover_max=80, lim=100, url='https://cmr.earthdata.nasa.gov/stac/LPCLOUD', collections=['HLSL30.v2.0', 'HLSS30.v2.0']):\n",
    "    # open the catalog\n",
    "    catalog = Client.open(f'{url}')\n",
    "    \n",
    "    # perform the search\n",
    "    search = catalog.search(\n",
    "        collections=collections,\n",
    "        intersects=pt,\n",
    "        datetime=dt_min + '/' + dt_max,\n",
    "        limit=lim\n",
    "    )\n",
    "\n",
    "    links = []\n",
    "\n",
    "    if search.matched() == 0:\n",
    "        print('No granules found at point', pt, 'from', dt_min, 'to', dt_max)\n",
    "    else:\n",
    "        print('Found', search.matched(), 'granules at point', pt, 'from', dt_min, 'to', dt_max)\n",
    "        item_collection = search.get_all_items()\n",
    "        \n",
    "        for i in item_collection:\n",
    "            if i.properties['eo:cloud_cover'] <= cloudcover_max:\n",
    "                if len(links) == 0:\n",
    "                    print(i.properties)\n",
    "                for a in i.assets:\n",
    "                    asset_href = i.assets[a].href\n",
    "                    filename = os.path.basename(asset_href)  # Extract filename from URL\n",
    "                    local_path = os.path.join('local_directory', filename)  # Specify local directory\n",
    "                    if not os.path.exists(local_path):\n",
    "                        # Download the asset if it doesn't exist locally\n",
    "                        download_asset(asset_href, local_path)\n",
    "                    links.append(local_path)\n",
    "\n",
    "    return links\n",
    "\n",
    "def download_asset(url, local_path):\n",
    "    # Download the asset from the URL to the local path\n",
    "    with open(local_path, 'wb') as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded '{url}' to '{local_path}'\")\n",
    "\n",
    "# Example usage\n",
    "# pt = {'type': 'Point', 'coordinates': [longitude, latitude]}  # Specify longitude and latitude\n",
    "# dt_min = 'start_date'  # Specify start date\n",
    "# dt_max = 'end_date'  # Specify end date\n",
    "\n",
    "# Search and download HLS data locally\n",
    "# asset_links = search_stac_for_HLS(pt, dt_min, dt_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hls_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     22\u001b[0m local_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/akz-workhorse/programming/NASA-Hackathon/HLS_data\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[0;32m---> 23\u001b[0m download_hls_assets(\u001b[43mhls_links\u001b[49m, local_directory)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hls_links' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_hls_assets(hls_links, local_directory):\n",
    "    if not os.path.exists(local_directory):\n",
    "        os.makedirs(local_directory)\n",
    "    for link in hls_links:\n",
    "        filename = link.split('/')[-1]  # Extract filename from URL\n",
    "        local_path = os.path.join(local_directory, filename)  # Specify local directory\n",
    "        if not os.path.exists(local_path):\n",
    "            # Download the asset if it doesn't exist locally\n",
    "            download_asset(link, local_path)\n",
    "\n",
    "def download_asset(url, local_path):\n",
    "    # Download the asset from the URL to the local path\n",
    "    with open(local_path, 'wb') as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded '{url}' to '{local_path}'\")\n",
    "\n",
    "# Example usage\n",
    "local_directory = '/home/akz-workhorse/programming/NASA-Hackathon/HLS_data'  \n",
    "download_hls_assets(hls_links, local_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.S3 at 0x78597581fdd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import requests\n",
    "\n",
    "# Define your bearer token\n",
    "bearer_token = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImFsaWtoYW4zNzU0NCIsImV4cCI6MTcxOTI1MDgyMCwiaWF0IjoxNzE0MDY2ODIwLCJpc3MiOiJFYXJ0aGRhdGEgTG9naW4ifQ.tWiFf3sbkK-PFEDvAbMFXoaTjjxnOMJfm0Ed6eW4xlcvXtKKfaZxoJGkejW2N7xlpf0_eDrKy_TcB8kfPdQIngPXqa9-lpVgFml2LPosJyMDw2h6nN7PVOuc_qGYPEJdn3lO7b_BllEiB2Z1TGkEEL-UU-4LIODluDyztVcImyxd66RpNqrgBRqa1wCLWLP7SZxlnq0dHLIXsfYJMuGJuqf7s3yTD-y0kprxpVRVgzIYGUuPZD2SgtTiBGwaRDURZE78YvWJ5550poT2YjfeigOenCFyBWZGoGsOFJRdhE6hRHobD8Ep018cMg908CC5-viZ9d5UfIbiuIg-JAckJA\"\n",
    "\n",
    "# Use the bearer token to authenticate\n",
    "session = boto3.Session()\n",
    "session.client('s3', config=boto3.session.Config(signature_version='s3v4'), \n",
    "               aws_access_key_id='', aws_secret_access_key='', aws_session_token=bearer_token)\n",
    "\n",
    "# Now you can use the session object to interact with AWS services\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Session(region_name=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rasterio.env.Env at 0x785975772d50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
